{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data Ready\n",
    "\n",
    "Forecasting is used in a variety of applications and business use cases: For example, retailers need to forecast the sales of their products to decide how much stock they need by location, Manufacturers need to estimate the number of parts required at their factories to optimize their supply chain, Businesses need to estimate their flexible workforce needs, Utilities need to forecast electricity consumption needs in order to attain an efficient energy network, and enterprises need to estimate their cloud infrastructure needs.\n",
    "\n",
    "<img src=\"https://amazon-forecast-samples.s3-us-west-2.amazonaws.com/common/images/forecast_overview_steps.png\" width=\"98%\">\n",
    "\n",
    "In this notebook we will be walking through the first steps outlined in left-box above.\n",
    "\n",
    "\n",
    "## Table Of Contents\n",
    "* Step 1: [Setup Amazon Forecast](#setup)\n",
    "* Step 2: [Prepare the Datasets](#DataPrep)\n",
    "* Step 3: [Create the Dataset Group and Dataset](#DataSet)\n",
    "* Step 4: [Create the Target Time Series Data Import Job](#DataImport)\n",
    "* [Next Steps](#nextSteps)\n",
    "\n",
    "For more informations about APIs, please check the [documentation](https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Amazon Forecast<a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section sets up the permissions and relevant endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.20.46)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.21.9-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 7.9 MB/s            \n",
      "\u001b[?25hCollecting botocore<1.25.0,>=1.24.9\n",
      "  Downloading botocore-1.24.9-py3-none-any.whl (8.6 MB)\n",
      "     |████████████████████████████████| 8.6 MB 64.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.25.0,>=1.24.9->boto3) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.25.0,>=1.24.9->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.9->boto3) (1.15.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.23.46\n",
      "    Uninstalling botocore-1.23.46:\n",
      "      Successfully uninstalled botocore-1.23.46\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.20.46\n",
      "    Uninstalling boto3-1.20.46:\n",
      "      Successfully uninstalled boto3-1.20.46\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.46 requires botocore==1.23.46, but you have botocore 1.24.9 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.24.9 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.21.9 botocore-1.24.9\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# importing forecast notebook utility from notebooks/common directory\n",
    "sys.path.insert( 0, os.path.abspath(\"./common\") )\n",
    "import util\n",
    "\n",
    "%reload_ext autoreload\n",
    "import boto3\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is your forecast horizon in number time units you've selected?\n",
    "# e.g. if you're forecasting in months, how many months out do you want a forecast?\n",
    "FORECAST_LENGTH = 8\n",
    "\n",
    "# What is your forecast time unit granularity?\n",
    "# Choices are: ^Y|M|W|D|H|30min|15min|10min|5min|1min$ \n",
    "DATASET_FREQUENCY = \"W\"\n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd\"\n",
    "\n",
    "# What name do you want to give this project?  \n",
    "# We will use this same name for your Forecast Dataset Group name.\n",
    "PROJECT = 'm5_sku_prediction_2m'\n",
    "DATA_VERSION = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the S3 bucket name and region name for this lesson.\n",
    "\n",
    "- If you don't have an S3 bucket, create it first on S3. \n",
    "- Although we have set the region to us-west-2 as a default value below, you can choose any of the regions that the service is available in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import sagemaker \n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "bucket_name = sagemaker.session.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect API session\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecastquery = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create IAM Role for Forecast</b> <br>\n",
    "Like many AWS services, Forecast will need to assume an IAM role in order to interact with your S3 resources securely. In the sample notebooks, we use the get_or_create_iam_role() utility function to create an IAM role. Please refer to \"notebooks/common/util/fcst_utils.py\" for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Role ForecastNotebookRole ...\n",
      "Created arn:aws:iam::080438298673:role/ForecastNotebookRole\n",
      "Attaching policies...\n",
      "Waiting for a minute to allow IAM role policy attachment to propagate\n",
      "Done.\n",
      "Success! Created role arn = ForecastNotebookRole\n"
     ]
    }
   ],
   "source": [
    "# Create the role to provide to Amazon Forecast.\n",
    "role_name = \"ForecastNotebookRole\"\n",
    "print(f\"Creating Role {role_name} ...\")\n",
    "role_arn = util.get_or_create_iam_role( role_name = role_name )\n",
    "\n",
    "# echo user inputs without account\n",
    "print(f\"Success! Created role arn = {role_arn.split('/')[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Datasets<a class=\"anchor\" id=\"DataPrep\"></a>\n",
    "\n",
    "For this exercise, we use the individual household electric power consumption dataset. (Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.) We aggregate the usage data hourly. \n",
    "\n",
    "To begin, use Pandas to read the CSV and to show a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>demand</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>3</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>3</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_011</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_013</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_016</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>4</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066732</th>\n",
       "      <td>FOODS_2_078</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>3</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066733</th>\n",
       "      <td>FOODS_2_081</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>3</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066734</th>\n",
       "      <td>FOODS_2_082</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066735</th>\n",
       "      <td>FOODS_2_083</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066736</th>\n",
       "      <td>FOODS_2_084</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2066737 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id   timestamp  demand store_id state_id\n",
       "0        FOODS_1_001  2011-01-29       3     CA_1       CA\n",
       "1        FOODS_1_005  2011-01-29       3     CA_1       CA\n",
       "2        FOODS_1_011  2011-01-29       2     CA_1       CA\n",
       "3        FOODS_1_013  2011-01-29       2     CA_1       CA\n",
       "4        FOODS_1_016  2011-01-29       4     CA_1       CA\n",
       "...              ...         ...     ...      ...      ...\n",
       "2066732  FOODS_2_078  2016-04-24       3     WI_3       WI\n",
       "2066733  FOODS_2_081  2016-04-24       3     WI_3       WI\n",
       "2066734  FOODS_2_082  2016-04-24       1     WI_3       WI\n",
       "2066735  FOODS_2_083  2016-04-24       1     WI_3       WI\n",
       "2066736  FOODS_2_084  2016-04-24       1     WI_3       WI\n",
       "\n",
       "[2066737 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tts_file = \"./processed_demands.csv\"\n",
    "df = pd.read_csv(tts_file, header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the output above there are 3 columns of data:\n",
    "\n",
    "1. The Timestamp\n",
    "1. A Value\n",
    "1. An Item ID\n",
    "\n",
    "These are the 3 key required pieces of information to generate a forecast with Amazon Forecast. More can be added but these 3 must always remain present.\n",
    "\n",
    "The dataset happens to span January 01, 2014 to Deceber 31, 2014. We are only going to use January to October to train Amazon Forecast.\n",
    "\n",
    "You may notice a variable named `df` this is a popular convention when using Pandas if you are using the library's dataframe object, it is similar to a table in a database. You can learn more here: https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time the data is ready to be sent to S3 where Forecast will use it later. The following cells will upload the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_key=f\"m5/{PROJECT}_{DATA_VERSION}/m5-demand-time-train.csv\"\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(tt_key).upload_file(tts_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Meta Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = './item_meta.csv'\n",
    "\n",
    "meta_df = pd.read_csv(meta_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  dept_id cat_id\n",
       "0  FOODS_1_001  FOODS_1  FOODS\n",
       "1  FOODS_1_002  FOODS_1  FOODS\n",
       "2  FOODS_1_003  FOODS_1  FOODS\n",
       "3  FOODS_1_004  FOODS_1  FOODS\n",
       "4  FOODS_1_005  FOODS_1  FOODS"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_key=f\"m5/{PROJECT}_{DATA_VERSION}/m5-item-meta.csv\"\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(meta_key).upload_file(meta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Related Time Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rts_file = './related_ts.csv'\n",
    "rts_file = './related_ts.csv'\n",
    "rts_df = pd.read_csv(rts_file, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_002</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_003</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_004</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_005</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738995</th>\n",
       "      <td>FOODS_2_080</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738996</th>\n",
       "      <td>FOODS_2_081</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738997</th>\n",
       "      <td>FOODS_2_082</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738998</th>\n",
       "      <td>FOODS_2_083</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738999</th>\n",
       "      <td>FOODS_2_084</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5739000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id   timestamp store_id state_id event_type_1 event_type_2  \\\n",
       "0        FOODS_1_001  2011-01-29     CA_1       CA      unknown      unknown   \n",
       "1        FOODS_1_002  2011-01-29     CA_1       CA      unknown      unknown   \n",
       "2        FOODS_1_003  2011-01-29     CA_1       CA      unknown      unknown   \n",
       "3        FOODS_1_004  2011-01-29     CA_1       CA      unknown      unknown   \n",
       "4        FOODS_1_005  2011-01-29     CA_1       CA      unknown      unknown   \n",
       "...              ...         ...      ...      ...          ...          ...   \n",
       "5738995  FOODS_2_080  2016-04-24     WI_3       WI      unknown      unknown   \n",
       "5738996  FOODS_2_081  2016-04-24     WI_3       WI      unknown      unknown   \n",
       "5738997  FOODS_2_082  2016-04-24     WI_3       WI      unknown      unknown   \n",
       "5738998  FOODS_2_083  2016-04-24     WI_3       WI      unknown      unknown   \n",
       "5738999  FOODS_2_084  2016-04-24     WI_3       WI      unknown      unknown   \n",
       "\n",
       "         snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0              0        0        0        2.00  \n",
       "1              0        0        0        7.88  \n",
       "2              0        0        0        2.88  \n",
       "3              0        0        0         NaN  \n",
       "4              0        0        0        2.94  \n",
       "...          ...      ...      ...         ...  \n",
       "5738995        0        0        0        2.18  \n",
       "5738996        0        0        0        2.38  \n",
       "5738997        0        0        0        5.98  \n",
       "5738998        0        0        0        6.72  \n",
       "5738999        0        0        0        2.97  \n",
       "\n",
       "[5739000 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_key=f\"m5/{PROJECT}_{DATA_VERSION}/m5-rts.csv\"\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(rts_key).upload_file(rts_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Dataset Group and Dataset <a class=\"anchor\" id=\"DataSet\"></a>\n",
    "\n",
    "In Amazon Forecast , a dataset is a collection of file(s) which contain data that is relevant for a forecasting task. A dataset must conform to a schema provided by Amazon Forecast. Since data files are imported headerless, it is important to define a schema for your data.\n",
    "\n",
    "More details about `Domain` and dataset type can be found on the [documentation](https://docs.aws.amazon.com/forecast/latest/dg/howitworks-domains-ds-types.html) . For this example, we are using [CUSTOM](https://docs.aws.amazon.com/forecast/latest/dg/custom-domain.html) domain with 3 required attributes `timestamp`, `target_value` and `item_id`.\n",
    "\n",
    "\n",
    "Next, you need to make some choices. \n",
    "<ol>\n",
    "    <li><b>How many time units do you want to forecast?</b>. For example, if your time unit is Hour, then if you want to forecast out 1 week, that would be 24*7 = 168 hours, so answer = 168. </li>\n",
    "    <li><b>What is the time granularity for your data?</b>. For example, if your time unit is Hour, answer = \"H\". </li>\n",
    "    <li><b>Think of a name you want to give this project (Dataset Group name)</b>, so all files will have the same names.  You should also use this same name for your Forecast DatasetGroup name, to set yourself up for reproducibility. </li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dataset Group\n",
    "\n",
    "In this task, we define a container name or Dataset Group name, which will be used to keep track of Dataset import files, schema, and all Forecast results which go together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Group Name = m5_sku_prediction_2m_4\n"
     ]
    }
   ],
   "source": [
    "dataset_group = f\"{PROJECT}_{DATA_VERSION}\"\n",
    "print(f\"Dataset Group Name = {dataset_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arns = []\n",
    "create_dataset_group_response = \\\n",
    "    forecast.create_dataset_group(Domain=\"RETAIL\",\n",
    "                                  DatasetGroupName=dataset_group,\n",
    "                                  DatasetArns=dataset_arns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:us-west-2:080438298673:dataset-group/m5_sku_prediction_2m_4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_group_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetGroupName': 'm5_sku_prediction_2m_4',\n",
       " 'DatasetGroupArn': 'arn:aws:forecast:us-west-2:080438298673:dataset-group/m5_sku_prediction_2m_4',\n",
       " 'DatasetArns': [],\n",
       " 'Domain': 'RETAIL',\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 19000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 19000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'b32bd28f-dc34-4200-8704-255b3160d0ae',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:25:13 GMT',\n",
       "   'x-amzn-requestid': 'b32bd28f-dc34-4200-8704-255b3160d0ae',\n",
       "   'content-length': '267',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_group(DatasetGroupArn=dataset_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        store_id\tstate_id\n",
    "# item_id\ttimestamp\tdemand\tlocation\n",
    "ts_schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"demand\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"store_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"state_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }\n",
    "\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5_sku_prediction_2m_4_tts\n"
     ]
    }
   ],
   "source": [
    "ts_dataset_name = f\"{PROJECT}_{DATA_VERSION}_tts\"\n",
    "print(ts_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \\\n",
    "forecast.create_dataset(Domain=\"RETAIL\",\n",
    "                        DatasetType='TARGET_TIME_SERIES',\n",
    "                        DatasetName=ts_dataset_name,\n",
    "                        DataFrequency=DATASET_FREQUENCY,\n",
    "                        Schema=ts_schema\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset_arn = response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-west-2:080438298673:dataset/m5_sku_prediction_2m_4_tts',\n",
       " 'DatasetName': 'm5_sku_prediction_2m_4_tts',\n",
       " 'Domain': 'RETAIL',\n",
       " 'DatasetType': 'TARGET_TIME_SERIES',\n",
       " 'DataFrequency': 'W',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'item_id',\n",
       "    'AttributeType': 'string'},\n",
       "   {'AttributeName': 'timestamp', 'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'demand', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'store_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'state_id', 'AttributeType': 'string'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 188000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 188000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'eb042f52-6f56-4b5d-b4fb-7770efbc9039',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:25:12 GMT',\n",
       "   'x-amzn-requestid': 'eb042f52-6f56-4b5d-b4fb-7770efbc9039',\n",
       "   'content-length': '615',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset(DatasetArn=ts_dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Meta Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_id\tproduct_type\tsegment\n",
    "# product_type\tsegmentation\tstyle_code\tcolor_code\titem_style\n",
    "# ['item_id', 'ListingPrice', \n",
    "#        'SAPLevel1Code', 'SAPLevel2Code', 'SAPLevel3Code', 'SAPLevel4Code',\n",
    "#        'SAPLevel6Code', 'SAPLevel7Code', 'SAPLevel8Code', 'SAPLevel9Code',\n",
    "#         'MaterialType']\n",
    "# dept_id\tcat_id\n",
    "meta_schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }, \n",
    "      \n",
    "      {\n",
    "         \"AttributeName\":\"dept_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"cat_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5_sku_prediction_2m_4_mt\n"
     ]
    }
   ],
   "source": [
    "meta_dataset_name = f\"{PROJECT}_{DATA_VERSION}_mt\"\n",
    "print(meta_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \\\n",
    "forecast.create_dataset(Domain=\"RETAIL\",\n",
    "                        DatasetType='ITEM_METADATA',\n",
    "                        DatasetName=meta_dataset_name,\n",
    "                        Schema=meta_schema\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_arn = response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-west-2:080438298673:dataset/m5_sku_prediction_2m_4_mt',\n",
       " 'DatasetName': 'm5_sku_prediction_2m_4_mt',\n",
       " 'Domain': 'RETAIL',\n",
       " 'DatasetType': 'ITEM_METADATA',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'item_id',\n",
       "    'AttributeType': 'string'},\n",
       "   {'AttributeName': 'dept_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'cat_id', 'AttributeType': 'string'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 374000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 374000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '0fcd5500-d9d0-4353-a96e-3f1ca50dd2f3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:25:13 GMT',\n",
       "   'x-amzn-requestid': '0fcd5500-d9d0-4353-a96e-3f1ca50dd2f3',\n",
       "   'content-length': '476',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset(DatasetArn = meta_dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Related Time Series Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rolling_mean_t4\trolling_std_t4\trolling_mean_t12\trolling_mean_t24\n",
    "# store_id,state_id,event_type_1,event_type_2,snap_CA,snap_TX,snap_WI,sell_price\n",
    "\n",
    "rts_schema ={\n",
    "    \"Attributes\": [\n",
    "        {\n",
    "             \"AttributeName\":\"item_id\",\n",
    "             \"AttributeType\":\"string\"\n",
    "        },\n",
    "        {\n",
    "             \"AttributeName\":\"timestamp\",\n",
    "             \"AttributeType\":\"timestamp\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"store_id\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"state_id\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"AttributeName\": \"event_type_1\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"event_type_2\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"snap_CA\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"snap_TX\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"snap_WI\",\n",
    "            \"AttributeType\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"sell_price\",\n",
    "            \"AttributeType\": \"float\"\n",
    "        },\n",
    "#         {\n",
    "#             \"AttributeName\": \"rolling_mean_t1\",\n",
    "#             \"AttributeType\": \"float\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"AttributeName\": \"rolling_mean_t2\",\n",
    "#             \"AttributeType\": \"float\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"AttributeName\": \"rolling_mean_t4\",\n",
    "#             \"AttributeType\": \"float\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"AttributeName\": \"rolling_mean_t12\",\n",
    "#             \"AttributeType\": \"float\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"AttributeName\": \"rolling_mean_t24\",\n",
    "#             \"AttributeType\": \"float\"\n",
    "#         }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5_sku_prediction_2m_4_rts\n"
     ]
    }
   ],
   "source": [
    "rts_dataset_name = f\"{PROJECT}_{DATA_VERSION}_rts\"\n",
    "print(rts_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \\\n",
    "forecast.create_dataset(Domain=\"RETAIL\",\n",
    "                            DatasetType='RELATED_TIME_SERIES',\n",
    "                            DatasetName=rts_dataset_name,\n",
    "                            DataFrequency=DATASET_FREQUENCY,\n",
    "                            Schema=rts_schema\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_dataset_arn = response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-west-2:080438298673:dataset/m5_sku_prediction_2m_4_rts',\n",
       " 'DatasetName': 'm5_sku_prediction_2m_4_rts',\n",
       " 'Domain': 'RETAIL',\n",
       " 'DatasetType': 'RELATED_TIME_SERIES',\n",
       " 'DataFrequency': 'W',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'item_id',\n",
       "    'AttributeType': 'string'},\n",
       "   {'AttributeName': 'timestamp', 'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'store_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'state_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'event_type_1', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'event_type_2', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'snap_CA', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'snap_TX', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'snap_WI', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'sell_price', 'AttributeType': 'float'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 505000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2022, 3, 1, 13, 25, 13, 505000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '0b4d678a-4f54-4543-88ca-a00350d728e1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:25:13 GMT',\n",
       "   'x-amzn-requestid': '0b4d678a-4f54-4543-88ca-a00350d728e1',\n",
       "   'content-length': '895',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset(DatasetArn = rts_dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataset group with the datasets we created\n",
    "You can have multiple datasets under the same dataset group. Update it with the datasets we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4766f62e-f557-4e4c-a767-ab7d0291123a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:25:13 GMT',\n",
       "   'x-amzn-requestid': '4766f62e-f557-4e4c-a767-ab7d0291123a',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_arns = []\n",
    "dataset_arns.append(ts_dataset_arn)\n",
    "dataset_arns.append(rts_dataset_arn)\n",
    "dataset_arns.append(meta_dataset_arn)\n",
    "forecast.update_dataset_group(DatasetGroupArn=dataset_group_arn, DatasetArns=dataset_arns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a Target Time Series Dataset Import Job <a class=\"anchor\" id=\"DataImport\"></a>\n",
    "\n",
    "\n",
    "Now that Forecast knows how to understand the CSV we are providing, the next step is to import the data from S3 into Amazon Forecaast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 URI for your data file = s3://sagemaker-us-west-2-080438298673/m5/m5_sku_prediction_2m_4/m5-demand-time-train.csv\n"
     ]
    }
   ],
   "source": [
    "# Recall path to your data\n",
    "ts_s3_data_path = \"s3://\"+bucket_name+\"/\"+tt_key\n",
    "print(f\"S3 URI for your data file = {ts_s3_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=dataset_group,\n",
    "                                       DatasetArn=ts_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": ts_s3_data_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       },\n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:us-west-2:080438298673:dataset-import-job/m5_sku_prediction_2m_4_tts/m5_sku_prediction_2m_4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset_import_job_arn=ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "ts_dataset_import_job_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of dataset, when the status change from **CREATE_IN_PROGRESS** to **ACTIVE**, we can continue to next steps. Depending on the data size. It can take 10 mins to be **ACTIVE**. This process will take 5 to 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PENDING ..\n",
      "CREATE_IN_PROGRESS ..........................................\n",
      "ACTIVE \n"
     ]
    }
   ],
   "source": [
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))\n",
    "assert status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetImportJobName': 'm5_sku_prediction_2m_4',\n",
       " 'DatasetImportJobArn': 'arn:aws:forecast:us-west-2:080438298673:dataset-import-job/m5_sku_prediction_2m_4_tts/m5_sku_prediction_2m_4',\n",
       " 'DatasetArn': 'arn:aws:forecast:us-west-2:080438298673:dataset/m5_sku_prediction_2m_4_tts',\n",
       " 'TimestampFormat': 'yyyy-MM-dd',\n",
       " 'UseGeolocationForTimeZone': False,\n",
       " 'DataSource': {'S3Config': {'Path': 's3://sagemaker-us-west-2-080438298673/m5/m5_sku_prediction_2m_4/m5-demand-time-train.csv',\n",
       "   'RoleArn': 'arn:aws:iam::080438298673:role/ForecastNotebookRole'}},\n",
       " 'FieldStatistics': {'demand': {'Count': 2066737,\n",
       "   'CountDistinct': 122,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '1.0',\n",
       "   'Max': '166.0',\n",
       "   'Avg': 3.2724187934894475,\n",
       "   'Stddev': 4.081777847905018,\n",
       "   'CountLong': 2066737,\n",
       "   'CountDistinctLong': 122,\n",
       "   'CountNullLong': 0,\n",
       "   'CountNanLong': 0},\n",
       "  'item_id': {'Count': 2066737,\n",
       "   'CountDistinct': 300,\n",
       "   'CountNull': 0,\n",
       "   'CountLong': 2066737,\n",
       "   'CountDistinctLong': 300,\n",
       "   'CountNullLong': 0},\n",
       "  'state_id': {'Count': 2066737,\n",
       "   'CountDistinct': 3,\n",
       "   'CountNull': 0,\n",
       "   'CountLong': 2066737,\n",
       "   'CountDistinctLong': 3,\n",
       "   'CountNullLong': 0},\n",
       "  'store_id': {'Count': 2066737,\n",
       "   'CountDistinct': 10,\n",
       "   'CountNull': 0,\n",
       "   'CountLong': 2066737,\n",
       "   'CountDistinctLong': 10,\n",
       "   'CountNullLong': 0},\n",
       "  'timestamp': {'Count': 2066737,\n",
       "   'CountDistinct': 1911,\n",
       "   'CountNull': 0,\n",
       "   'Min': '2011-01-29T00:00:00Z',\n",
       "   'Max': '2016-04-24T00:00:00Z',\n",
       "   'CountLong': 2066737,\n",
       "   'CountDistinctLong': 1911,\n",
       "   'CountNullLong': 0}},\n",
       " 'DataSize': 0.06362874992191792,\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2022, 3, 1, 13, 25, 14, 222000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2022, 3, 1, 13, 32, 47, 502000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '4e009d0d-07fa-4178-9a10-1ea32097cb75',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 Mar 2022 13:32:56 GMT',\n",
       "   'x-amzn-requestid': '4e009d0d-07fa-4178-9a10-1ea32097cb75',\n",
       "   'content-length': '1453',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a Item Meta Data Dataset Import Job <a class=\"anchor\" id=\"DataImport\"></a>\n",
    "\n",
    "\n",
    "Now that Forecast knows how to understand the CSV we are providing, the next step is to import the data from S3 into Amazon Forecaast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 URI for your data file = s3://sagemaker-us-west-2-080438298673/m5/m5_sku_prediction_2m_4/m5-item-meta.csv\n"
     ]
    }
   ],
   "source": [
    "# Recall path to your data\n",
    "meta_s3_data_path = \"s3://\"+bucket_name+\"/\"+meta_key\n",
    "print(f\"S3 URI for your data file = {meta_s3_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=dataset_group,\n",
    "                                       DatasetArn=meta_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": meta_s3_data_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         },  \n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:us-west-2:080438298673:dataset/m5_sku_prediction_2m_4_mt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:us-west-2:080438298673:dataset-import-job/m5_sku_prediction_2m_4_mt/m5_sku_prediction_2m_4'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset_import_job_arn=meta_dataset_import_job_response['DatasetImportJobArn']\n",
    "meta_dataset_import_job_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m5_sku_prediction_2m_4'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PENDING \n",
      "CREATE_IN_PROGRESS ...........\n",
      "ACTIVE \n"
     ]
    }
   ],
   "source": [
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=meta_dataset_import_job_arn))\n",
    "assert status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Related Time Series Dataset Import Job <a class=\"anchor\" id=\"DataImport\"></a>\n",
    "\n",
    "\n",
    "Now that Forecast knows how to understand the CSV we are providing, the next step is to import the data from S3 into Amazon Forecaast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 URI for your data file = s3://sagemaker-us-west-2-080438298673/m5/m5_sku_prediction_2m_4/m5-rts.csv\n"
     ]
    }
   ],
   "source": [
    "# Recall path to your data\n",
    "rts_s3_data_path = \"s3://\"+bucket_name+\"/\"+rts_key\n",
    "print(f\"S3 URI for your data file = {rts_s3_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=dataset_group,\n",
    "                                       DatasetArn=rts_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": rts_s3_data_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       }, \n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-080438298673/m5/m5_sku_prediction_2m_4/m5-rts.csv'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rts_s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:us-west-2:080438298673:dataset-import-job/m5_sku_prediction_2m_4_rts/m5_sku_prediction_2m_4'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rts_dataset_import_job_arn=rts_dataset_import_job_response['DatasetImportJobArn']\n",
    "rts_dataset_import_job_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PENDING .\n",
      "CREATE_IN_PROGRESS .......................\n",
      "ACTIVE \n"
     ]
    }
   ],
   "source": [
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=rts_dataset_import_job_arn))\n",
    "assert status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps<a class=\"anchor\" id=\"nextSteps\"></a>\n",
    "\n",
    "At this point you have successfully imported your data into Amazon Forecast and now it is time to get started in the next notebook to build your first model. To Continue, execute the cell below to store important variables where they can be used in the next notebook, then open `2.Building_Your_Predictor.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'PROJECT' (str)\n",
      "Stored 'DATA_VERSION' (int)\n",
      "Stored 'FORECAST_LENGTH' (int)\n",
      "Stored 'DATASET_FREQUENCY' (str)\n",
      "Stored 'TIMESTAMP_FORMAT' (str)\n",
      "Stored 'ts_dataset_import_job_arn' (str)\n",
      "Stored 'ts_dataset_arn' (str)\n",
      "Stored 'dataset_group_arn' (str)\n",
      "Stored 'role_arn' (str)\n",
      "Stored 'bucket_name' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'tt_key' (str)\n"
     ]
    }
   ],
   "source": [
    "# Now save your choices for the next notebook \n",
    "# %store item_id\n",
    "%store PROJECT\n",
    "%store DATA_VERSION\n",
    "%store FORECAST_LENGTH\n",
    "%store DATASET_FREQUENCY\n",
    "%store TIMESTAMP_FORMAT\n",
    "%store ts_dataset_import_job_arn\n",
    "%store ts_dataset_arn\n",
    "%store dataset_group_arn\n",
    "%store role_arn\n",
    "%store bucket_name\n",
    "%store region\n",
    "%store tt_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
